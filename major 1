{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1GK5e_OMZtZJggA7VqmQST9cvwA_GwIjh","authorship_tag":"ABX9TyMzlY7r8prQV/wjpxOBTKnK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ttxvP4Gv-Wqd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760886074421,"user_tz":-330,"elapsed":28356,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"708974dc-a7c9-4d98-ed60-3da7fef8b8c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (5.3.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Collecting SimpleITK\n","  Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.2 kB)\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from nibabel) (2.0.2)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel) (25.0)\n","Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel) (4.15.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.8.0+cu126)\n","Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.3)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n","Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.11)\n","Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK, lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed SimpleITK-2.5.2 lightning-utilities-0.15.2 pytorch-lightning-2.5.5 torchmetrics-1.8.2\n","Collecting git+https://github.com/wolny/pytorch-3dunet.git\n","  Cloning https://github.com/wolny/pytorch-3dunet.git to /tmp/pip-req-build-k1iuzrbh\n","  Running command git clone --filter=blob:none --quiet https://github.com/wolny/pytorch-3dunet.git /tmp/pip-req-build-k1iuzrbh\n","  Resolved https://github.com/wolny/pytorch-3dunet.git to commit 71bf82b6a87b4c69448fa20edd13ec314d95a616\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (0.23.0+cu126)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (2.0.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (2.19.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (4.67.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (3.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (1.16.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (0.25.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pytorch3dunet==1.9.6) (6.0.3)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pytorch3dunet==1.9.6) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pytorch3dunet==1.9.6) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pytorch3dunet==1.9.6) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pytorch3dunet==1.9.6) (2025.10.4)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pytorch3dunet==1.9.6) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pytorch3dunet==1.9.6) (0.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (1.75.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (3.9)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pytorch3dunet==1.9.6) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch3dunet==1.9.6) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pytorch3dunet==1.9.6) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->pytorch3dunet==1.9.6) (3.0.3)\n","Building wheels for collected packages: pytorch3dunet\n","  Building wheel for pytorch3dunet (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch3dunet: filename=pytorch3dunet-1.9.6-py3-none-any.whl size=64719 sha256=8a10ca0d0eff4884af364b8ddb96e7e6337916a4985e8c240cc0a5bb8eb27545\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-extnvjo6/wheels/ea/af/7f/87ad44ab4229e536cb66622761d19fde33b797c72bc5a6466e\n","Successfully built pytorch3dunet\n","Installing collected packages: pytorch3dunet\n","Successfully installed pytorch3dunet-1.9.6\n"]}],"source":["!pip install torch torchvision torchaudio\n","!pip install nibabel tqdm scikit-learn SimpleITK pytorch-lightning\n","!pip install git+https://github.com/wolny/pytorch-3dunet.git\n"]},{"cell_type":"code","source":["!pip install -q kaggle h5py              # code starting"],"metadata":{"id":"cOOIv93kOCn2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from google.colab import files\n","\n","# Upload kaggle.json\n","if not os.path.exists('/root/.kaggle/kaggle.json'):\n","    print(\"Please upload your 'kaggle.json' file.\")\n","    uploaded = files.upload()\n","\n","    if 'kaggle.json' in uploaded:\n","        !mkdir -p /root/.kaggle\n","        !mv kaggle.json /root/.kaggle/\n","        !chmod 600 /root/.kaggle/kaggle.json\n","        print(\"Kaggle API token uploaded successfully.\")\n","    else:\n","        print(\"File upload failed or was not 'kaggle.json'. Please try again.\")\n","else:\n","    print(\"Kaggle API token already exists.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"id":"vVJbaxJ8OJ7P","executionInfo":{"status":"error","timestamp":1761678643449,"user_tz":-330,"elapsed":116674,"user":{"displayName":"","userId":""}},"outputId":"1996efa5-c61a-40fa-ac78-6008e6a9e689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Please upload your 'kaggle.json' file.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-cbcb2e8d-c95a-47a1-99b0-208a0af5d4d2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cbcb2e8d-c95a-47a1-99b0-208a0af5d4d2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2045028991.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.kaggle/kaggle.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please upload your 'kaggle.json' file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'kaggle.json'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!kaggle datasets download -d awsaf49/brats20-dataset-training-validation"],"metadata":{"id":"Piz-9ZoYOfJ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","\n","with zipfile.ZipFile('brats20-dataset-training-validation.zip', 'r') as zip_ref:\n","    zip_ref.extractall('brats_data')\n","\n","print(\"Dataset extracted.\")"],"metadata":{"id":"BMb0W_6UOmLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","import h5py\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import glob\n","\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","# Define Constants\n","IMG_HEIGHT = 128\n","IMG_WIDTH = 128\n","IMG_DEPTH = 128\n","IMG_CHANNELS = 4  # FLAIR, T1, T1ce, T2\n","NUM_CLASSES = 3   # Edema, Tumor Core, Enhancing Tumor\n","\n","# Data Paths\n","TRAIN_DATA_DIR = 'brats_data/BraTS20_Training_data/'\n","VALID_DATA_DIR = 'brats_data/BraTS20_Validation_data/'\n","\n","\n","BATCH_SIZE = 2  # Adjust based on your Colab GPU (A100 can handle 2 or 4)\n","EPOCHS = 30     # Start with 30-50 for testing, 100+ for final paper\n","SMOOTH = 1e-6\n"],"metadata":{"id":"bEW02mnwO1c1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_and_preprocess_h5(file_path):\n","    \"\"\"\n","    Loads a single HDF5 file and preprocesses the mask.\n","    \"\"\"\n","    with h5py.File(file_path, \"r\") as f:\n","        # Image: (128, 128, 128, 4) - Already normalized\n","        image = f['image'][:]\n","\n","        # Mask: (128, 128, 128, 3) - (WT, TC, ET)\n","        mask = f['mask'][:]\n","\n","    # --- Create the 3-class target mask ---\n","    # 1. Enhancing Tumor (ET)\n","    mask_et = mask[..., 2:3]  # Shape (128, 128, 128, 1)\n","\n","    # 2. Tumor Core (TC)\n","    mask_tc = mask[..., 1:2]  # Shape (128, 128, 128, 1)\n","\n","    # 3. Edema\n","    # WT is channel 0, TC is channel 1\n","    mask_wt = mask[..., 0:1]\n","    mask_edema = mask_wt - mask_tc  # WT - TC = Edema\n","    mask_edema = np.clip(mask_edema, 0, 1) # Ensure no negative values\n","\n","    # Stack the 3 target classes\n","    # Our model will predict: (Edema, Tumor Core, Enhancing Tumor)\n","    processed_mask = np.concatenate([mask_edema, mask_tc, mask_et], axis=-1)\n","\n","    # Convert to float32\n","    image = tf.convert_to_tensor(image, dtype=tf.float32)\n","    processed_mask = tf.convert_to_tensor(processed_mask, dtype=tf.float32)\n","\n","    return image, processed_mask\n"],"metadata":{"id":"gxjpUul2O7rA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_generator_wrapper(file_list):\n","    \"\"\"Wraps the h5 loader for use in tf.data.\"\"\"\n","    for file_path in file_list:\n","        yield load_and_preprocess_h5(file_path)\n","\n","def get_dataset(file_list, batch_size, shuffle=True):\n","    \"\"\"Creates a tf.data.Dataset from a list of H5 files.\"\"\"\n","\n","    # Create a dataset from the generator\n","    dataset = tf.data.Dataset.from_generator(\n","        lambda: data_generator_wrapper(file_list),\n","        output_signature=(\n","            tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS), dtype=tf.float32),\n","            tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, NUM_CLASSES), dtype=tf.float32)\n","        )\n","    )\n","\n","    if shuffle:\n","        # Shuffle files. Using file_list length for buffer_size is a good default.\n","        dataset = dataset.shuffle(len(file_list))\n","\n","    # Batch, prefetch for performance\n","    dataset = dataset.batch(batch_size, drop_remainder=True)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset\n","\n","# Get file lists\n","train_files = sorted(glob.glob(os.path.join(TRAIN_DATA_DIR, 'data_*.h5')))\n","valid_files = sorted(glob.glob(os.path.join(VALID_DATA_DIR, 'data_*.h5')))\n","\n","print(f\"Found {len(train_files)} training files.\")\n","print(f\"Found {len(valid_files)} validation files.\")\n","\n","# Create the tf.data.Dataset objects\n","train_dataset = get_dataset(train_files, BATCH_SIZE, shuffle=True)\n","valid_dataset = get_dataset(valid_files, BATCH_SIZE, shuffle=False)\n","\n","# Test the generator\n","print(\"\\nTesting data generator...\")\n","for images, masks in train_dataset.take(1):\n","    print(f\"  Image batch shape: {images.shape}\")\n","    print(f\"  Mask batch shape:  {masks.shape}\")\n","    print(f\"  Image dtype: {images.dtype}\")\n","    print(f\"  Mask dtype:  {masks.dtype}\")\n","    print(f\"  Mask min/max: {np.min(masks)}, {np.max(masks)}\")"],"metadata":{"id":"ynnT2fAaPewv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conv_block(inputs, num_filters):\n","    x = layers.Conv3D(num_filters, 3, padding=\"same\")(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","\n","    x = layers.Conv3D(num_filters, 3, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","\n","    return x\n","\n","def encoder_block(inputs, num_filters):\n","    x = conv_block(inputs, num_filters)\n","    p = layers.MaxPooling3D((2, 2, 2))(x)\n","    return x, p\n","\n","def decoder_block(inputs, skip_features, num_filters):\n","    x = layers.Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(inputs)\n","    x = layers.Concatenate()([x, skip_features])\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","def build_3d_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS),\n","                  num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(input_shape)\n","\n","    # Encoder\n","    s1, p1 = encoder_block(inputs, 64)\n","    s2, p2 = encoder_block(p1, 128)\n","    s3, p3 = encoder_block(p2, 256)\n","\n","    # Bottleneck\n","    b1 = conv_block(p3, 512)\n","\n","    # Decoder\n","    d1 = decoder_block(b1, s3, 256)\n","    d2 = decoder_block(d1, s2, 128)\n","    d3 = decoder_block(d2, s1, 64)\n","\n","    # Output layer\n","    # We are doing 3-class, multi-label segmentation (each pixel can be Edema, Core, or ET)\n","    # So we use 3 filters and 'sigmoid' activation.\n","    outputs = layers.Conv3D(num_classes, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n","\n","    model = Model(inputs, outputs, name=\"3D_U-Net\")\n","    return model\n","\n","# Build and summarize the model\n","model = build_3d_unet()\n","model.summary()"],"metadata":{"id":"S5cShML9PlUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bce_loss = tf.keras.losses.BinaryCrossentropy()\n","\n","# --- Loss Function 2: Dice Loss ---\n","def dice_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(y_pred, tf.float32)\n","\n","    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1,2,3)) + SMOOTH\n","    denominator = tf.reduce_sum(y_true + y_pred, axis=(1,2,3)) + SMOOTH\n","\n","    # Average loss over batch and classes\n","    return 1 - tf.reduce_mean(numerator / denominator)"],"metadata":{"id":"mmKHayqDP9_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Loss Function 3: Tversky Loss ---\n","# A generalization of Dice loss.\n","# alpha=0.5, beta=0.5 -> Dice Loss\n","# alpha=0.3, beta=0.7 -> Emphasizes False Negatives (good for sparse data)\n","def create_tversky_loss(alpha=0.3, beta=0.7):\n","    def tversky_loss(y_true, y_pred):\n","        y_true = tf.cast(y_true, tf.float32)\n","        y_pred = tf.cast(y_pred, tf.float32)\n","\n","        tp = tf.reduce_sum(y_true * y_pred, axis=(1,2,3))\n","        fn = tf.reduce_sum(y_true * (1 - y_pred), axis=(1,2,3))\n","        fp = tf.reduce_sum((1 - y_true) * y_pred, axis=(1,2,3))\n","\n","        tversky_index = (tp + SMOOTH) / (tp + alpha * fn + beta * fp + SMOOTH)\n","\n","        # Average loss over batch and classes\n","        return 1 - tf.reduce_mean(tversky_index)\n","\n","    return tversky_loss\n","\n","tversky_loss = create_tversky_loss()"],"metadata":{"id":"iQWr-d_lQT9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Loss Function 4: Focal Loss ---\n","# A modification of BCE to focus on \"hard\" examples.\n","def create_focal_loss(alpha=0.25, gamma=2.0):\n","    def focal_loss(y_true, y_pred):\n","        y_true = tf.cast(y_true, tf.float32)\n","        y_pred = tf.cast(y_pred, tf.float32)\n","\n","        # Standard BCE\n","        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n","\n","        # Focal Loss components\n","        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n","        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n","        modulating_factor = tf.pow(1.0 - p_t, gamma)\n","\n","        # Final loss\n","        loss = alpha_factor * modulating_factor * bce\n","\n","        # Average over all dimensions\n","        return tf.reduce_mean(loss)\n","\n","    return focal_loss\n","\n","focal_loss = create_focal_loss()"],"metadata":{"id":"6rzUHSe8Qb8b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Loss Function 5: Hybrid Loss (BCE + Dice) ---\n","def hybrid_loss(y_true, y_pred, bce_weight=0.5, dice_weight=0.5):\n","    loss_bce = bce_loss(y_true, y_pred)\n","    loss_dice = dice_loss(y_true, y_pred)\n","\n","    return (bce_weight * loss_bce) + (dice_weight * loss_dice)\n","\n","print(\"All loss functions defined.\")\n"],"metadata":{"id":"BC8BprzcQh7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dice_coefficient(y_true, y_pred, class_index):\n","    \"\"\"Calculates Dice score for a specific class.\"\"\"\n","    y_true_class = y_true[..., class_index]\n","    y_pred_class = y_pred[..., class_index]\n","\n","    # Threshold prediction\n","    y_pred_class = tf.cast(y_pred_class > 0.5, tf.float32)\n","    y_true_class = tf.cast(y_true_class, tf.float32)\n","\n","    numerator = 2 * tf.reduce_sum(y_true_class * y_pred_class) + SMOOTH\n","    denominator = tf.reduce_sum(y_true_class + y_pred_class) + SMOOTH\n","    return numerator / denominator\n","\n","def iou_metric(y_true, y_pred, class_index):\n","    \"\"\"Calculates IoU score for a specific class.\"\"\"\n","    y_true_class = y_true[..., class_index]\n","    y_pred_class = y_pred[..., class_index]\n","\n","    # Threshold prediction\n","    y_pred_class = tf.cast(y_pred_class > 0.5, tf.float32)\n","    y_true_class = tf.cast(y_true_class, tf.float32)\n","\n","    intersection = tf.reduce_sum(y_true_class * y_pred_class)\n","    union = tf.reduce_sum(y_true_class + y_pred_class) - intersection + SMOOTH\n","    return (intersection + SMOOTH) / union\n","\n","# --- Metric Wrapper Functions ---\n","# We create separate metrics for each class, as this is what your paper will report.\n","\n","# Class 0: Edema\n","def dice_edema(y_true, y_pred):\n","    return dice_coefficient(y_true, y_pred, 0)\n","\n","def iou_edema(y_true, y_pred):\n","    return iou_metric(y_true, y_pred, 0)\n","\n","# Class 1: Tumor Core\n","def dice_core(y_true, y_pred):\n","    return dice_coefficient(y_true, y_pred, 1)\n","\n","def iou_core(y_true, y_pred):\n","    return iou_metric(y_true, y_pred, 1)\n","\n","# Class 2: Enhancing Tumor\n","def dice_enhancing(y_true, y_pred):\n","    return dice_coefficient(y_true, y_pred, 2)\n","\n","def iou_enhancing(y_true, y_pred):\n","    return iou_metric(y_true, y_pred, 2)\n","\n","\n","# List of all metrics for compilation\n","METRICS = [\n","    dice_edema, iou_edema,\n","    dice_core, iou_core,\n","    dice_enhancing, iou_enhancing\n","]\n","\n","print(f\"Defined {len(METRICS)} metrics.\")"],"metadata":{"id":"3u0yPllvQuTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses_to_test = {\n","    \"Binary_CrossEntropy\": bce_loss,\n","    \"Dice_Loss\": dice_loss,\n","    \"Tversky_Loss_a0.3_b0.7\": tversky_loss,\n","    \"Focal_Loss_a0.25_g2.0\": focal_loss,\n","    \"Hybrid_Loss_BCE+Dice\": hybrid_loss\n","}\n","\n","# Store results\n","experiment_histories = {}\n","\n","def run_experiment(loss_name, loss_function, train_ds, val_ds, epochs):\n","    \"\"\"\n","    Builds, compiles, and trains a new 3D U-Net model.\n","    \"\"\"\n","    print(\"-\" * 60)\n","    print(f\"Starting Experiment: Training with {loss_name}\")\n","    print(\"-\" * 60)\n","\n","    # Clear session and build a new model for a clean experiment\n","    tf.keras.backend.clear_session()\n","    model = build_3d_unet()\n","\n","    # Compile the model\n","    model.compile(\n","        optimizer=Adam(learning_rate=1e-4),\n","        loss=loss_function,\n","        metrics=METRICS\n","    )\n","\n","    # Callbacks\n","    callbacks = [\n","        tf.keras.callbacks.ModelCheckpoint(\n","            f\"model_{loss_name}.keras\",\n","            verbose=1,\n","            save_best_only=True,\n","            monitor=\"val_dice_core\" # Monitor core tumor dice score\n","        ),\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor=\"val_loss\",\n","            patience=10,\n","            restore_best_weights=True\n","        ),\n","        tf.keras.callbacks.ReduceLROnPlateau(\n","            monitor=\"val_loss\",\n","            factor=0.2,\n","            patience=5\n","        )\n","    ]\n","\n","    # Train the model\n","    history = model.fit(\n","        train_ds,\n","        epochs=epochs,\n","        validation_data=val_ds,\n","        callbacks=callbacks\n","    )\n","\n","    print(f\"Finished Experiment: {loss_name}\")\n","    return history\n","\n","# --- Run all experiments ---\n","# WARNING: This will take a *long* time.\n","# On a Colab A100, one experiment at 30 epochs might take ~1-2 hours.\n","# For your FYP, you may want to run this overnight.\n","# For initial testing, set EPOCHS = 5\n","\n","for loss_name, loss_func in losses_to_test.items():\n","    history = run_experiment(\n","        loss_name,\n","        loss_func,\n","        train_dataset,\n","        valid_dataset,\n","        epochs=EPOCHS\n","    )\n","    experiment_histories[loss_name] = history\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"All experiments complete.\")\n","print(\"=\"*60)"],"metadata":{"id":"m9JXPdrMQ34S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_histories(histories, metric_prefix, plot_val=True):\n","    plt.figure(figsize=(15, 10))\n","\n","    for name, history in histories.items():\n","        plt.plot(history.history[metric_prefix], label=f'{name} (Train)', linestyle='--')\n","\n","\n","    if plot_val:\n","        val_metric = f'val_{metric_prefix}'\n","        for name, history in histories.items():\n","            if val_metric in history.history:\n","                plt.plot(history.history[val_metric], label=f'{name} (Val)', linewidth=2)\n","\n","    plt.title(f'Model Comparison: {metric_prefix.upper()}')\n","    plt.ylabel(metric_prefix.replace(\"_\", \" \").title())\n","    plt.xlabel('Epoch')\n","    plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1))\n","    plt.grid(True)\n","    plt.show()"],"metadata":{"id":"F2oSkakaQ6wZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_histories(experiment_histories, 'loss')"],"metadata":{"id":"GPgq_eDERY3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_histories(experiment_histories, 'dice_core')\n"],"metadata":{"id":"PkXZlHHLRcOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_histories(experiment_histories, 'dice_enhancing')"],"metadata":{"id":"dbJUdkaORemi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_histories(experiment_histories, 'dice_edema')"],"metadata":{"id":"tlp9M_xHRgzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BEST_MODEL_NAME = \"Hybrid_Loss_BCE+Dice\"\n","best_model_path = f\"model_{BEST_MODEL_NAME}.keras\"\n","\n","print(f\"Loading best model: {best_model_path}\")\n","\n","\n","custom_objects = {\n","    \"hybrid_loss\": hybrid_loss,\n","    \"dice_loss\": dice_loss,\n","    \"tversky_loss\": tversky_loss,\n","    \"focal_loss\": focal_loss,\n","    \"dice_edema\": dice_edema,\n","    \"iou_edema\": iou_edema,\n","    \"dice_core\": dice_core,\n","    \"iou_core\": iou_core,\n","    \"dice_enhancing\": dice_enhancing,\n","    \"iou_enhancing\": iou_enhancing\n","}\n","\n","\n","best_model = tf.keras.models.load_model(best_model_path, custom_objects=custom_objects)\n","print(\"Model loaded successfully.\")\n","print(f\"Evaluating '{BEST_MODEL_NAME}' on the full validation set...\")\n","evaluation_results = best_model.evaluate(valid_dataset)\n","\n","print(\"\\n--- Final Validation Metrics ---\")\n","metric_names = ['loss'] + [m.__name__ for m in METRICS]\n","for name, value in zip(metric_names, evaluation_results):\n","    print(f\"  {name}: {value:.4f}\")"],"metadata":{"id":"P4q7I5aKRkAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_prediction(model, dataset):\n","    \"\"\"\n","    Picks one batch from the dataset, predicts, and plots the results.\n","    \"\"\"\n","    # Get one batch\n","    for image_batch, mask_batch in dataset.take(1):\n","        # Predict\n","        pred_batch = model.predict(image_batch)\n","\n","        # Pick the first item in the batch\n","        image = image_batch[0]  # (128, 128, 128, 4)\n","        mask = mask_batch[0]    # (128, 128, 128, 3)\n","        pred = pred_batch[0]    # (128, 128, 128, 3)\n","\n","        # Threshold the prediction\n","        pred = (pred > 0.5).astype(np.float32)\n","\n","        # Choose a slice (e.g., slice 75) to display\n","        slice_idx = 75\n","\n","        # Input modalities for context\n","        flair = image[:, :, slice_idx, 0]\n","        t1ce = image[:, :, slice_idx, 2]\n","\n","        # Ground Truth Masks\n","        mask_edema = mask[:, :, slice_idx, 0]\n","        mask_core = mask[:, :, slice_idx, 1]\n","        mask_enhancing = mask[:, :, slice_idx, 2]\n","\n","        # Predicted Masks\n","        pred_edema = pred[:, :, slice_idx, 0]\n","        pred_core = pred[:, :, slice_idx, 1]\n","        pred_enhancing = pred[:, :, slice_idx, 2]\n","\n","        # --- Plotting ---\n","        fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n","        fig.suptitle(f\"Segmentation Results (Slice {slice_idx})\", fontsize=20)\n","\n","        # --- Row 1: Edema (Class 0) ---\n","        axes[0, 0].imshow(flair, cmap='gray')\n","        axes[0, 0].set_title(\"Input: FLAIR\")\n","        axes[0, 0].axis('off')\n","\n","        axes[0, 1].imshow(mask_edema, cmap='Reds', vmin=0, vmax=1)\n","        axes[0, 1].set_title(\"GT: Edema\")\n","        axes[0, 1].axis('off')\n","\n","        axes[0, 2].imshow(pred_edema, cmap='Reds', vmin=0, vmax=1)\n","        axes[0, 2].set_title(\"Pred: Edema\")\n","        axes[0, 2].axis('off')\n","\n","        axes[0, 3].imshow(flair, cmap='gray')\n","        axes[0, 3].imshow(pred_edema, cmap='Reds', alpha=0.5, vmin=0, vmax=1)\n","        axes[0, 3].set_title(\"Overlay: Pred Edema\")\n","        axes[0, 3].axis('off')\n","\n","        # --- Row 2: Tumor Core (Class 1) ---\n","        axes[1, 0].imshow(t1ce, cmap='gray')\n","        axes[1, 0].set_title(\"Input: T1ce\")\n","        axes[1, 0].axis('off')\n","\n","        axes[1, 1].imshow(mask_core, cmap='Greens', vmin=0, vmax=1)\n","        axes[1, 1].set_title(\"GT: Tumor Core\")\n","        axes[1, 1].axis('off')\n","\n","        axes[1, 2].imshow(pred_core, cmap='Greens', vmin=0, vmax=1)\n","        axes[1, 2].set_title(\"Pred: Tumor Core\")\n","        axes[1, 2].axis('off')\n","\n","        axes[1, 3].imshow(t1ce, cmap='gray')\n","        axes[1, 3].imshow(pred_core, cmap='Greens', alpha=0.5, vmin=0, vmax=1)\n","        axes[1, 3].set_title(\"Overlay: Pred Core\")\n","        axes[1, 3].axis('off')\n","\n","        # --- Row 3: Enhancing Tumor (Class 2) ---\n","        axes[2, 0].imshow(t1ce, cmap='gray')\n","        axes[2, 0].set_title(\"Input: T1ce\")\n","        axes[2, 0].axis('off')\n","\n","        axes[2, 1].imshow(mask_enhancing, cmap='Blues', vmin=0, vmax=1)\n","        axes[2, 1].set_title(\"GT: Enhancing Tumor\")\n","        axes[2, 1].axis('off')\n","\n","        axes[2, 2].imshow(pred_enhancing, cmap='Blues', vmin=0, vmax=1)\n","        axes[2, 2].set_title(\"Pred: Enhancing Tumor\")\n","        axes[2, 2].axis('off')\n","\n","        axes[2, 3].imshow(t1ce, cmap='gray')\n","        axes[2, 3].imshow(pred_enhancing, cmap='Blues', alpha=0.5, vmin=0, vmax=1)\n","        axes[2, 3].set_title(\"Overlay: Pred Enhancing\")\n","        axes[2, 3].axis('off')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","# Visualize predictions from the best model\n","visualize_prediction(best_model, valid_dataset)"],"metadata":{"id":"XkuPvdCrRwUC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PBPAn_t_Wg0","executionInfo":{"status":"ok","timestamp":1760886115766,"user_tz":-330,"elapsed":13490,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"51382480-c6ab-4d2b-e9a4-60b9ad5160db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/FYP_BrainTumorSeg/\n","!mkdir -p data/brats2021 outputs\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLQc3aSi_dzD","executionInfo":{"status":"ok","timestamp":1760886130357,"user_tz":-330,"elapsed":173,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"93826cd3-0573-4899-a5b4-5e1d445446ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/FYP_BrainTumorSeg/'\n","/content\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5dQP7v2yAq5l"},"execution_count":null,"outputs":[]}]}