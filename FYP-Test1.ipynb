{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMv75V6Q2A3IgqUs07CkT+U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9rjBIECVUcp","executionInfo":{"status":"ok","timestamp":1761932173106,"user_tz":-330,"elapsed":85550,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"ffeab3e5-0457-4623-f677-3e6844ba9129"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m626.8/626.8 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q kaggle\n","!pip install -q nibabel\n","!pip install -q scikit-learn\n","!pip install -q tqdm\n","!pip install -q split-folders\n","!pip install -q torchinfo\n","!pip install -q segmentation-models-pytorch-3d\n","!pip install -q livelossplot\n","!pip install -q torchmetrics\n","!pip install -q tensorboard\n","!pip install -q matplotlib seaborn plotly\n","!pip install -q opencv-python-headless\n","!pip install -q pandas numpy"]},{"cell_type":"code","source":["import os\n","import random\n","import glob\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import nibabel as nib\n","import cv2\n","from tqdm import tqdm\n","import splitfolders\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import AdamW, Adam\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n","import torchvision.transforms as transforms\n","from torch.cuda import amp\n","from torchmetrics import MeanMetric, Dice, JaccardIndex\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall\n","import torchinfo\n","import segmentation_models_pytorch_3d as smp\n","from livelossplot import PlotLosses\n","from livelossplot.outputs import MatplotlibPlot\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"collapsed":true,"id":"1vA6DmLOVluL","executionInfo":{"status":"error","timestamp":1761932211401,"user_tz":-330,"elapsed":18346,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"2933ef4c-a588-45cd-dd48-72d7f1f82624"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'Dice' from 'torchmetrics' (/usr/local/lib/python3.12/dist-packages/torchmetrics/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1656221165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeanMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJaccardIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticlassAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMulticlassPrecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMulticlassRecall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Dice' from 'torchmetrics' (/usr/local/lib/python3.12/dist-packages/torchmetrics/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(42)"],"metadata":{"id":"74UbpcoPVuVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n"],"metadata":{"id":"Fc9nUB0cVz3J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","print(\"Please upload your Kaggle API credentials (kaggle.json)\")\n","print(\"Instructions: Go to https://www.kaggle.com/account â†’ Create API Token\")\n","files.upload()"],"metadata":{"id":"d1JTRI8NWOAu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"QGLbap0PWTsY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Downloading BraTS 2021 dataset...\")\n","!kaggle datasets download -d dschettler8845/brats-2021-task1\n","!unzip -q brats-2021-task1.zip -d /content/BraTS2021/\n","!rm -f brats-2021-task1.zip\n","DATASET_PATH = \"/content/BraTS2021/\"\n","print(f\"Dataset extracted to: {DATASET_PATH}\")\n","print(f\"Total files in dataset: {len(os.listdir(DATASET_PATH))}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"collapsed":true,"id":"RwdaS_ETWbp6","executionInfo":{"status":"error","timestamp":1761932389807,"user_tz":-330,"elapsed":34,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"1bbea062-83c6-488e-d0c3-51be31d2ebd0"},"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"incomplete input (ipython-input-735401617.py, line 7)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-735401617.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(f\"Total files in dataset: {len(os.listdir(DATASET_PATH))}\"\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"]}]},{"cell_type":"code","source":["t1_list = sorted(glob.glob(f\"{DATASET_PATH}/BraTS2021_*/*/*t1.nii\"))\n","t1ce_list = sorted(glob.glob(f\"{DATASET_PATH}/BraTS2021_*/*/*t1ce.nii\"))\n","t2_list = sorted(glob.glob(f\"{DATASET_PATH}/BraTS2021_*/*/*t2.nii\"))\n","flair_list = sorted(glob.glob(f\"{DATASET_PATH}/BraTS2021_*/*/*flair.nii\"))\n","mask_list = sorted(glob.glob(f\"{DATASET_PATH}/BraTS2021_*/*/*seg.nii\"))\n","print(f\"Found files:\")\n","print(f\"T1: {len(t1_list)}\")\n","print(f\"T1ce: {len(t1ce_list)}\")\n","print(f\"T2: {len(t2_list)}\")\n","print(f\"FLAIR: {len(flair_list)}\")\n","print(f\"Masks: {len(mask_list)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"collapsed":true,"id":"zFKGdeHkWijO","executionInfo":{"status":"error","timestamp":1761932496485,"user_tz":-330,"elapsed":33,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"f148a70f-98a0-46cd-ee71-880c64e71bf0"},"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'DATASET_PATH' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3877533919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATASET_PATH}/BraTS2021_*/*/*t1.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt1ce_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATASET_PATH}/BraTS2021_*/*/*t1ce.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt2_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATASET_PATH}/BraTS2021_*/*/*t2.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflair_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATASET_PATH}/BraTS2021_*/*/*flair.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmask_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATASET_PATH}/BraTS2021_*/*/*seg.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'DATASET_PATH' is not defined"]}]},{"cell_type":"code","source":["def preprocess_data():\n","    \"\"\"\n","    Preprocesses BraTS 2021 data: scales, crops, and saves as numpy arrays.\n","    Implements ROI cropping to reduce computational requirements.\n","    \"\"\"\n","    scaler = MinMaxScaler()\n","    os.makedirs(\"BraTS2021_Preprocessed/images\", exist_ok=True)\n","    os.makedirs(\"BraTS2021_Preprocessed/masks\", exist_ok=True)\n","  for idx in tqdm(range(min(len(t1_list), 500)), desc=\"Preprocessing samples\"):\n","        try:\n","\n","            t1 = nib.load(t1_list[idx]).get_fdata()\n","            t1ce = nib.load(t1ce_list[idx]).get_fdata()\n","            t2 = nib.load(t2_list[idx]).get_fdata()\n","            flair = nib.load(flair_list[idx]).get_fdata()\n","            mask = nib.load(mask_list[idx]).get_fdata().astype(np.uint8)\n","\n","\n","            t1 = scaler.fit_transform(t1.reshape(-1, 1)).reshape(t1.shape)\n","            t1ce = scaler.fit_transform(t1ce.reshape(-1, 1)).reshape(t1ce.shape)\n","            t2 = scaler.fit_transform(t2.reshape(-1, 1)).reshape(t2.shape)\n","            flair = scaler.fit_transform(flair.reshape(-1, 1)).reshape(flair.shape)\n","\n","\n","            combined_images = np.stack([flair, t1ce, t2, t1], axis=3)\n","\n","\n","            combined_images = combined_images[56:184, 56:184, 13:141]\n","            mask = mask[56:184, 56:184, 13:141]\n","\n","\n","            tumor_pixels = np.sum(mask > 0)\n","            total_pixels = mask.size\n","            tumor_ratio = tumor_pixels / total_pixels\n","\n","            if tumor_ratio > 0.01:\n","                np.save(f\"BraTS2021_Preprocessed/images/image_{idx:04d}.npy\", combined_images)\n","                np.save(f\"BraTS2021_Preprocessed/masks/mask_{idx:04d}.npy\", mask)\n","                valid_samples += 1\n","              except Exception as e:\n","            print(f\"Error processing sample {idx}: {e}\")\n","            continue\n","\n","    print(f\"Preprocessing complete. Valid samples: {valid_samples}\")\n","    return valid_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"collapsed":true,"id":"U1d-DxlLW8Ci","executionInfo":{"status":"error","timestamp":1761964813999,"user_tz":-330,"elapsed":57,"user":{"displayName":"ams","userId":"16908876361288379684"}},"outputId":"3add1cfc-4dc9-4b8a-cf5c-cc127ac0c4b2"},"execution_count":2,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"unindent does not match any outer indentation level (<tokenize>, line 9)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    for idx in tqdm(range(min(len(t1_list), 500)), desc=\"Preprocessing samples\"):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"]}]},{"cell_type":"code","source":["num_valid_samples = preprocess_data()"],"metadata":{"id":"6U9XCbhPSVCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_folder = \"BraTS2021_Preprocessed/\"\n","output_folder = \"BraTS2021_Split/\"\n","\n","splitfolders.ratio(\n","    input_folder,\n","    output=output_folder,\n","    seed=42,\n","    ratio=(0.8, 0.2),\n","    group_prefix=None\n",")\n","\n","print(\"Data split completed:\")\n","print(f\"Train: {len(os.listdir(os.path.join(output_folder, 'train/images')))} samples\")\n","print(f\"Val: {len(os.listdir(os.path.join(output_folder, 'val/images')))} samples\")"],"metadata":{"id":"cG1BZ5wPSd9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BraTSDataset(Dataset):\n","    \"\"\"\n","    Custom Dataset for BraTS 2021 brain tumor segmentation.\n","    Handles 3D medical image loading and preprocessing.\n","    \"\"\"\n","\n","    def __init__(self, img_dir, mask_dir, normalize=True, augment=False):\n","        self.img_dir = img_dir\n","        self.mask_dir = mask_dir\n","        self.normalize = normalize\n","        self.augment = augment\n","\n","        self.img_list = sorted(os.listdir(img_dir))\n","        self.mask_list = sorted(os.listdir(mask_dir))\n","\n","\n","        if self.normalize:\n","            self.mean = torch.tensor([0.5, 0.5, 0.5, 0.5]).view(4, 1, 1, 1)\n","            self.std = torch.tensor([0.5, 0.5, 0.5, 0.5]).view(4, 1, 1, 1)\n","\n","    def __len__(self):\n","        return len(self.img_list)\n","\n","    def __getitem__(self, idx):\n","\n","        img_path = os.path.join(self.img_dir, self.img_list[idx])\n","        mask_path = os.path.join(self.mask_dir, self.mask_list[idx])\n","\n","        image = np.load(img_path)\n","        mask = np.load(mask_path)\n","\n","        image = torch.from_numpy(image).permute(3, 2, 0, 1).float()\n","        mask = torch.from_numpy(mask).long()\n","\n","\n","        if self.normalize:\n","            image = (image - self.mean) / self.std\n","\n","\n","        if self.augment:\n","            image, mask = self.augment_data(image, mask)\n","\n","        return image, mask\n","\n","    def augment_data(self, image, mask):\n","        \"\"\"Simple augmentation strategies for medical images\"\"\"\n","        if torch.rand(1) > 0.5:\n","            angle = torch.rand(1) * 0.1 - 0.05\n","            image = self.rotate_3d(image, angle)\n","            mask = self.rotate_3d(mask.float(), angle).long()\n","\n","        if torch.rand(1) > 0.5:\n","            noise = torch.randn_like(image) * 0.01\n","            image = image + noise\n","\n","        return image, mask\n","\n","    def rotate_3d(self, tensor, angle):\n","        \"\"\"Simple 3D rotation (placeholder - in practice, use specialized libraries)\"\"\"\n","        return tensor\n"],"metadata":{"id":"eMLeuzvJSjM3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_img_dir = os.path.join(output_folder, \"train/images\")\n","train_mask_dir = os.path.join(output_folder, \"train/masks\")\n","val_img_dir = os.path.join(output_folder, \"val/images\")\n","val_mask_dir = os.path.join(output_folder, \"val/masks\")\n","\n","train_dataset = BraTSDataset(train_img_dir, train_mask_dir, normalize=True, augment=True)\n","val_dataset = BraTSDataset(val_img_dir, val_mask_dir, normalize=True, augment=False)\n"],"metadata":{"id":"TzYO4kYJS-0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 2  # Reduced for Colab memory constraints\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=2,\n","    pin_memory=True\n",")\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=2,\n","    pin_memory=True\n",")"],"metadata":{"id":"GygI0gTSTDJo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_image, sample_mask = train_dataset[0]\n","print(f\"Sample image shape: {sample_image.shape}\")\n","print(f\"Sample mask shape: {sample_mask.shape}\")\n","print(f\"Unique mask values: {torch.unique(sample_mask)}\")\n"],"metadata":{"id":"eXGGvK0UTHoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class DoubleConv(nn.Module):\n","    \"\"\"Double convolution block with batch normalization and dropout\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n","        super(DoubleConv, self).__init__()\n","        self.double_conv = nn.Sequential(\n","            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout3d(dropout_rate),\n","            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class UNet3D(nn.Module):\n","    \"\"\"Standard 3D U-Net for brain tumor segmentation\"\"\"\n","\n","    def __init__(self, in_channels=4, out_channels=4, features=[16, 32, 64, 128, 256]):\n","        super(UNet3D, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n","\n","        # Encoder (downsampling path)\n","        in_ch = in_channels\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_ch, feature))\n","            in_ch = feature\n","\n","        # Bottleneck\n","        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n","\n","        # Decoder (upsampling path)\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose3d(\n","                    feature * 2, feature, kernel_size=2, stride=2\n","                )\n","            )\n","            self.ups.append(DoubleConv(feature * 2, feature))\n","\n","        # Final classification layer\n","        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        # Encoder\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","\n","        # Decoder\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx // 2]\n","\n","            if x.shape != skip_connection.shape:\n","                x = F.interpolate(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx + 1](concat_skip)\n","\n","        return self.final_conv(x)"],"metadata":{"id":"Sm5Pv95vTMom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = UNet3D(in_channels=4, out_channels=4)\n","model = model.to(device)"],"metadata":{"id":"tRHj9I9iTaGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"3D U-Net Architecture Summary:\")\n","print(\"=\" * 50)\n","print(torchinfo.summary(model, input_size=(1, 4, 128, 128, 128)))"],"metadata":{"id":"q5zbzytFTkTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    test_input = torch.randn(1, 4, 128, 128, 128).to(device)\n","    test_output = model(test_input)\n","    print(f\"\\nTest Input Shape: {test_input.shape}\")\n","    print(f\"Test Output Shape: {test_output.shape}\")\n"],"metadata":{"id":"RBFgxdDyTov9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DiceLoss(nn.Module):\n","    \"\"\"Dice Loss for medical image segmentation\"\"\"\n","\n","    def __init__(self, smooth=1e-6):\n","        super(DiceLoss, self).__init__()\n","        self.smooth = smooth\n","\n","    def forward(self, pred, target):\n","        pred = torch.softmax(pred, dim=1)\n","        target = F.one_hot(target, num_classes=4).permute(0, 4, 1, 2, 3).float()\n","\n","        intersection = (pred * target).sum()\n","        union = pred.sum() + target.sum()\n","        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n","\n","        return 1 - dice.mean()\n","\n","class FocalLoss(nn.Module):\n","    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n","\n","    def __init__(self, alpha=1, gamma=2, smooth=1e-6):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smooth = smooth\n","\n","    def forward(self, pred, target):\n","        ce_loss = F.cross_entropy(pred, target, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n","\n","        return focal_loss.mean()\n","\n","class TverskyLoss(nn.Module):\n","    \"\"\"Tversky Loss for addressing false positives and false negatives\"\"\"\n","\n","    def __init__(self, alpha=0.7, beta=0.3, smooth=1e-6):\n","        super(TverskyLoss, self).__init__()\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.smooth = smooth\n","\n","    def forward(self, pred, target):\n","        pred = torch.softmax(pred, dim=1)\n","        target = F.one_hot(target, num_classes=4).permute(0, 4, 1, 2, 3).float()\n","\n","        tp = (pred * target).sum()\n","        fp = pred * (1 - target)\n","        fn = (1 - pred) * target\n","\n","        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)\n","\n","        return 1 - tversky.mean()\n","\n","class FocalTverskyLoss(nn.Module):\n","    \"\"\"Focal Tversky Loss combining focal and Tversky losses\"\"\"\n","\n","    def __init__(self, alpha=0.7, beta=0.3, gamma=4/3, smooth=1e-6):\n","        super(FocalTverskyLoss, self).__init__()\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.gamma = gamma\n","        self.smooth = smooth\n","\n","    def forward(self, pred, target):\n","        pred = torch.softmax(pred, dim=1)\n","        target = F.one_hot(target, num_classes=4).permute(0, 4, 1, 2, 3).float()\n","\n","        tp = (pred * target).sum()\n","        fp = pred * (1 - target)\n","        fn = (1 - pred) * target\n","\n","        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)\n","        focal_tversky = torch.pow(1 - tversky, self.gamma)\n","\n","        return focal_tversky.mean()\n","\n","class UnifiedFocalLoss(nn.Module):\n","    \"\"\"Unified Focal Loss combining Dice and Focal losses\"\"\"\n","\n","    def __init__(self, dice_weight=0.5, focal_weight=0.5, smooth=1e-6):\n","        super(UnifiedFocalLoss, self).__init__()\n","        self.dice_weight = dice_weight\n","        self.focal_weight = focal_weight\n","        self.smooth = smooth\n","        self.dice_loss = DiceLoss(smooth)\n","        self.focal_loss = FocalLoss()\n","\n","    def forward(self, pred, target):\n","        dice = self.dice_loss(pred, target)\n","        focal = self.focal_loss(pred, target)\n","\n","        return self.dice_weight * dice + self.focal_weight * focal\n","\n","class CombinedTverskyLoss(nn.Module):\n","    \"\"\"Combined Tversky and Focal Loss\"\"\"\n","\n","    def __init__(self, tversky_weight=0.7, focal_weight=0.3, alpha=0.7, beta=0.3, gamma=4/3):\n","        super(CombinedTverskyLoss, self).__init__()\n","        self.tversky_weight = tversky_weight\n","        self.focal_weight = focal_weight\n","        self.tversky_loss = TverskyLoss(alpha=alpha, beta=beta)\n","        self.focal_loss = FocalLoss(alpha=0.25, gamma=2.0)\n","\n","    def forward(self, pred, target):\n","        tversky = self.tversky_loss(pred, target)\n","        focal = self.focal_loss(pred, target)\n","\n","        return self.tversky_weight * tversky + self.focal_weight * focal"],"metadata":{"id":"Hi5CsxPVTsWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LOSS_FUNCTIONS = {\n","    'dice': DiceLoss(),\n","    'focal': FocalLoss(),\n","    'tversky': TverskyLoss(),\n","    'focal_tversky': FocalTverskyLoss(),\n","    'unified_focal': UnifiedFocalLoss(),\n","    'combined_tversky': CombinedTverskyLoss(),\n","    'dice_focal': CombinedTverskyLoss(tversky_weight=0.6, focal_weight=0.4),\n","    'ce_dice': None  # Will implement below\n","}\n"],"metadata":{"id":"N9y6MP1PT1G3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CEDiceLoss(nn.Module):\n","    def __init__(self, ce_weight=0.5, dice_weight=0.5):\n","        super(CEDiceLoss, self).__init__()\n","        self.ce_weight = ce_weight\n","        self.dice_weight = dice_weight\n","        self.ce_loss = nn.CrossEntropyLoss()\n","        self.dice_loss = DiceLoss()\n","\n","    def forward(self, pred, target):\n","        ce = self.ce_loss(pred, target)\n","        dice = self.dice_loss(pred, target)\n","\n","        return self.ce_weight * ce + self.dice_weight * dice\n","\n","LOSS_FUNCTIONS['ce_dice'] = CEDiceLoss()\n","\n","print(\"Implemented Loss Functions:\")\n","print(\"=\" * 30)\n","for loss_name in LOSS_FUNCTIONS.keys():\n","    print(f\"- {loss_name}\")"],"metadata":{"id":"WIhMiT3XT6q9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class TrainingConfig:\n","    \"\"\"Training configuration\"\"\"\n","    BATCH_SIZE = 2\n","    EPOCHS = 50\n","    LEARNING_RATE = 1e-3\n","    WEIGHT_DECAY = 1e-4\n","    SAVE_DIR = \"model_checkpoints\"\n","    NUM_CLASSES = 4\n","    INPUT_CHANNELS = 4\n","\n","# Create save directory\n","os.makedirs(TrainingConfig.SAVE_DIR, exist_ok=True)\n","\n","class MetricsCalculator:\n","    \"\"\"Calculate comprehensive metrics for segmentation evaluation\"\"\"\n","\n","    def __init__(self, num_classes=4):\n","        self.num_classes = num_classes\n","        self.dice_metric = Dice(num_classes=num_classes, average='macro')\n","        self.iou_metric = JaccardIndex(num_classes=num_classes, average='macro')\n","        self.accuracy_metric = MulticlassAccuracy(num_classes=num_classes, average='macro')\n","        self.precision_metric = MulticlassPrecision(num_classes=num_classes, average='macro')\n","        self.recall_metric = MulticlassRecall(num_classes=num_classes, average='macro')\n","\n","        self.reset()\n","\n","    def reset(self):\n","        \"\"\"Reset all metrics\"\"\"\n","        self.dice_metric.reset()\n","        self.iou_metric.reset()\n","        self.accuracy_metric.reset()\n","        self.precision_metric.reset()\n","        self.recall_metric.reset()\n","\n","    def update(self, pred, target):\n","        \"\"\"Update metrics with predictions and targets\"\"\"\n","        pred.argmax(dim=1)\n","        self.dice_metric.update(pred, target)\n","        self.iou_metric.update(pred, target)\n","        self.accuracy_metric.update(pred, target)\n","        self.precision_metric.update(pred, target)\n","        self.recall_metric.update(pred, target)\n","\n","    def compute(self):\n","        \"\"\"Compute all metrics\"\"\"\n","        return {\n","            'dice': self.dice_metric.compute().item(),\n","            'iou': self.iou_metric.compute().item(),\n","            'accuracy': self.accuracy_metric.compute().item(),\n","            'precision': self.precision_metric.compute().item(),\n","            'recall': self.recall_metric.compute().item()\n","        }\n","\n","def train_epoch(model, loader, loss_fn, optimizer, scheduler, scaler, metrics_calc):\n","    \"\"\"Train for one epoch\"\"\"\n","    model.train()\n","    metrics_calc.reset()\n","    total_loss = 0\n","\n","    for batch_idx, (data, target) in enumerate(loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Mixed precision training for memory efficiency\n","        with amp.autocast():\n","            output = model(data)\n","            loss = loss_fn(output, target)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        total_loss += loss.item()\n","        metrics_calc.update(output.detach(), target)\n","\n","        if batch_idx % 10 == 0:\n","            print(f'Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}')\n","\n","    avg_loss = total_loss / len(loader)\n","    metrics = metrics_calc.compute()\n","\n","    return avg_loss, metrics\n","\n","def validate_epoch(model, loader, loss_fn, metrics_calc):\n","    \"\"\"Validate for one epoch\"\"\"\n","    model.eval()\n","    metrics_calc.reset()\n","    total_loss = 0\n","\n","    with torch.no_grad():\n","        for data, target in loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = loss_fn(output, target)\n","\n","            total_loss += loss.item()\n","            metrics_calc.update(output, target)\n","\n","    avg_loss = total_loss / len(loader)\n","    metrics = metrics_calc.compute()\n","\n","    return avg_loss, metrics"],"metadata":{"id":"EP1HDWe-UB1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_with_loss_function(loss_name, loss_fn, epochs=50):\n","    \"\"\"Train model with specific loss function\"\"\"\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Training with {loss_name} loss function\")\n","    print(f\"{'='*60}\")\n","\n","\n","    model = UNet3D(in_channels=4, out_channels=4).to(device)\n","    optimizer = AdamW(model.parameters(), lr=TrainingConfig.LEARNING_RATE, weight_decay=TrainingConfig.WEIGHT_DECAY)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n","    scaler = amp.GradScaler()\n","    metrics_calc = MetricsCalculator()\n","\n","\n","    train_losses = []\n","    val_losses = []\n","    train_metrics = []\n","    val_metrics = []\n","    best_val_dice = 0\n","    best_model_state = None\n","\n","    for epoch in range(epochs):\n","        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n","        print(\"-\" * 30)\n","\n","\n","        train_loss, train_metrics_dict = train_epoch(model, train_loader, loss_fn, optimizer, scheduler, scaler, metrics_calc)\n","        train_losses.append(train_loss)\n","        train_metrics.append(train_metrics_dict)\n","\n","\n","        val_loss, val_metrics_dict = validate_epoch(model, val_loader, loss_fn, metrics_calc)\n","        val_losses.append(val_loss)\n","        val_metrics.append(val_metrics_dict)\n","\n","\n","        print(f\"Train Loss: {train_loss:.4f}, Train Dice: {train_metrics_dict['dice']:.4f}\")\n","        print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_metrics_dict['dice']:.4f}\")\n","\n","\n","        if val_metrics_dict['dice'] > best_val_dice:\n","            best_val_dice = val_metrics_dict['dice']\n","            best_model_state = model.state_dict().copy()\n","\n","\n","    model.load_state_dict(best_model_state)\n","\n","\n","    final_train_metrics = train_metrics[-1]\n","    final_val_metrics = val_metrics[-1]\n","\n","    results = {\n","        'loss_name': loss_name,\n","        'best_val_dice': best_val_dice,\n","        'final_train_dice': final_train_metrics['dice'],\n","        'final_val_dice': final_val_metrics['dice'],\n","        'final_train_iou': final_train_metrics['iou'],\n","        'final_val_iou': final_val_metrics['iou'],\n","        'final_train_acc': final_train_metrics['accuracy'],\n","        'final_val_acc': final_val_metrics['accuracy'],\n","        'train_losses': train_losses,\n","        'val_losses': val_losses,\n","        'train_metrics_history': train_metrics,\n","        'val_metrics_history': val_metrics,\n","        'model_state': best_model_state\n","    }\n","\n","    print(f\"\\n{loss_name} Results:\")\n","    print(f\"Best Val Dice: {best_val_dice:.4f}\")\n","    print(f\"Final Val Metrics - Dice: {final_val_metrics['dice']:.4f}, IoU: {final_val_metrics['iou']:.4f}\")\n","\n","    return results\n","\n","\n","print(\"Starting comprehensive loss function comparison...\")\n","print(\"This will train the 3D U-Net with each loss function and compare results.\")\n","\n","\n","all_results = {}\n","results_summary = []\n","\n","\n","EPOCHS_COMPARISON = 25\n","\n","for loss_name, loss_fn in LOSS_FUNCTIONS.items():\n","    print(f\"\\n\\nTraining with {loss_name}...\")\n","    try:\n","        results = train_with_loss_function(loss_name, loss_fn, EPOCHS_COMPARISON)\n","        all_results[loss_name] = results\n","\n","        results_summary.append({\n","            'Loss Function': loss_name,\n","            'Best Val Dice': results['best_val_dice'],\n","            'Final Val Dice': results['final_val_dice'],\n","            'Final Val IoU': results['final_val_iou'],\n","            'Final Val Accuracy': results['final_val_acc']\n","        })\n","\n","    except Exception as e:\n","        print(f\"Error training with {loss_name}: {e}\")\n","        continue"],"metadata":{"id":"mwb9JjCWUNXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_df = pd.DataFrame(results_summary)\n","results_df = results_df.sort_values('Best Val Dice', ascending=False)\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"LOSS FUNCTION COMPARISON RESULTS\")\n","print(\"=\"*80)\n","print(results_df.round(4))\n","\n","# Identify best loss function\n","best_loss_name = results_df.iloc[0]['Loss Function']\n","best_loss_result = all_results[best_loss_name]\n","\n","print(f\"\\nğŸ† BEST PERFORMING LOSS FUNCTION: {best_loss_name}\")\n","print(f\"Best Validation Dice Score: {best_loss_result['best_val_dice']:.4f}\")\n","print(f\"Final Validation Metrics:\")\n","print(f\"  - Dice: {best_loss_result['final_val_dice']:.4f}\")\n","print(f\"  - IoU: {best_loss_result['final_val_iou']:.4f}\")\n","print(f\"  - Accuracy: {best_loss_result['final_val_acc']:.4f}\")\n","\n","# Plot comparison metrics\n","plt.figure(figsize=(15, 12))\n","\n","# Loss curves comparison\n","plt.subplot(2, 2, 1)\n","for loss_name, results in all_results.items():\n","    plt.plot(results['train_losses'], label=f'{loss_name} (train)', alpha=0.7)\n","    plt.plot(results['val_losses'], label=f'{loss_name} (val)', alpha=0.7, linestyle='--')\n","plt.title('Training and Validation Losses')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.yscale('log')\n","\n","# Dice score comparison\n","plt.subplot(2, 2, 2)\n","dice_scores = [results['best_val_dice'] for results in all_results.values()]\n","loss_names = list(all_results.keys())\n","bars = plt.bar(loss_names, dice_scores)\n","plt.title('Best Validation Dice Scores')\n","plt.xlabel('Loss Function')\n","plt.ylabel('Dice Score')\n","plt.xticks(rotation=45)\n","\n","# Color the best performing bar\n","best_idx = loss_names.index(best_loss_name)\n","bars[best_idx].set_color('gold')\n","\n","# IoU comparison\n","plt.subplot(2, 2, 3)\n","iou_scores = [results['final_val_iou'] for results in all_results.values()]\n","bars = plt.bar(loss_names, iou_scores)\n","plt.title('Final Validation IoU Scores')\n","plt.xlabel('Loss Function')\n","plt.ylabel('IoU Score')\n","plt.xticks(rotation=45)\n","bars[best_idx].set_color('gold')\n","\n","# Accuracy comparison\n","plt.subplot(2, 2, 4)\n","acc_scores = [results['final_val_acc'] for results in all_results.values()]\n","bars = plt.bar(loss_names, acc_scores)\n","plt.title('Final Validation Accuracy')\n","plt.xlabel('Loss Function')\n","plt.ylabel('Accuracy')\n","plt.xticks(rotation=45)\n","bars[best_idx].set_color('gold')\n","\n","plt.tight_layout()\n","plt.savefig('loss_function_comparison.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# Detailed analysis of best loss function\n","plt.figure(figsize=(15, 5))\n","\n","plt.subplot(1, 3, 1)\n","plt.plot(best_loss_result['train_losses'], label='Train', color='blue')\n","plt.plot(best_loss_result['val_losses'], label='Validation', color='red')\n","plt.title(f'{best_loss_name} - Loss Curves')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.yscale('log')\n","\n","plt.subplot(1, 3, 2)\n","train_dice = [m['dice'] for m in best_loss_result['train_metrics_history']]\n","val_dice = [m['dice'] for m in best_loss_result['val_metrics_history']]\n","plt.plot(train_dice, label='Train Dice', color='blue')\n","plt.plot(val_dice, label='Validation Dice', color='red')\n","plt.title(f'{best_loss_name} - Dice Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('Dice Score')\n","plt.legend()\n","\n","plt.subplot(1, 3, 3)\n","train_iou = [m['iou'] for m in best_loss_result['train_metrics_history']]\n","val_iou = [m['iou'] for m in best_loss_result['val_metrics_history']]\n","plt.plot(train_iou, label='Train IoU', color='blue')\n","plt.plot(val_iou, label='Validation IoU', color='red')\n","plt.title(f'{best_loss_name} - IoU Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('IoU')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('best_loss_analysis.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","def visualize_predictions(model, loader, num_samples=6):\n","    \"\"\"Visualize model predictions on validation data\"\"\"\n","    model.eval()\n","\n","    fig, axes = plt.subplots(num_samples, 5, figsize=(20, 4*num_samples))\n","\n","    with torch.no_grad():\n","        for idx, (data, target) in enumerate(loader):\n","            if idx >= num_samples:\n","                break\n","\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            pred = torch.softmax(output, dim=1).argmax(dim=1)\n","\n","            # Get middle slice for visualization\n","            middle_slice = data.shape[2] // 2\n","\n","            # Original modalities (FLAIR as example)\n","            axes[idx, 0].imshow(data[idx, 0, middle_slice].cpu().numpy(), cmap='gray')\n","            axes[idx, 0].set_title('FLAIR')\n","\n","            # Ground truth\n","            axes[idx, 1].imshow(target[idx, middle_slice].cpu().numpy(), cmap='tab10')\n","            axes[idx, 1].set_title('Ground Truth')\n","\n","            # Prediction\n","            axes[idx, 2].imshow(pred[idx, middle_slice].cpu().numpy(), cmap='tab10')\n","            axes[idx, 2].set_title('Prediction')\n","\n","            # Overlay\n","            overlay = data[idx, 0, middle_slice].cpu().numpy()\n","            axes[idx, 3].imshow(overlay, cmap='gray', alpha=0.7)\n","            axes[idx, 3].imshow(pred[idx, middle_slice].cpu().numpy(), cmap='tab10', alpha=0.3)\n","            axes[idx, 3].set_title('Overlay')\n","\n","            # Metrics for this sample\n","            sample_metrics = MetricsCalculator()\n","            sample_metrics.update(output, target)\n","            metrics = sample_metrics.compute()\n","\n","            axes[idx, 4].axis('off')\n","            axes[idx, 4].text(0.1, 0.8, f'Sample {idx+1}', fontsize=12, fontweight='bold')\n","            axes[idx, 4].text(0.1, 0.6, f'Dice: {metrics[\"dice\"]:.3f}', fontsize=10)\n","            axes[idx, 4].text(0.1, 0.5, f'IoU: {metrics[\"iou\"]:.3f}', fontsize=10)\n","            axes[idx, 4].text(0.1, 0.4, f'Acc: {metrics[\"accuracy\"]:.3f}', fontsize=10)\n","            axes[idx, 4].text(0.1, 0.3, f'Prec: {metrics[\"precision\"]:.3f}', fontsize=10)\n","            axes[idx, 4].text(0.1, 0.2, f'Recall: {metrics[\"recall\"]:.3f}', fontsize=10)\n","\n","    plt.tight_layout()\n","    plt.savefig('predictions_visualization.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","# Load best model and visualize predictions\n","best_model = UNet3D(in_channels=4, out_channels=4).to(device)\n","best_model.load_state_dict(best_loss_result['model_state'])\n","\n","print(f\"\\nVisualizing predictions with {best_loss_name} loss function...\")\n","visualize_predictions(best_model, val_loader, num_samples=4)"],"metadata":{"id":"hrV15eeHUocn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model_path = f\"{TrainingConfig.SAVE_DIR}/best_3d_unet_{best_loss_name}.pth\"\n","torch.save({\n","    'model_state_dict': best_loss_result['model_state'],\n","    'loss_function': best_loss_name,\n","    'training_config': {\n","        'epochs': EPOCHS_COMPARISON,\n","        'learning_rate': TrainingConfig.LEARNING_RATE,\n","        'batch_size': TrainingConfig.BATCH_SIZE\n","    },\n","    'performance_metrics': {\n","        'best_val_dice': best_loss_result['best_val_dice'],\n","        'final_val_dice': best_loss_result['final_val_dice'],\n","        'final_val_iou': best_loss_result['final_val_iou'],\n","        'final_val_accuracy': best_loss_result['final_val_acc']\n","    }\n","}, best_model_path)\n","\n","print(f\"\\nBest model saved to: {best_model_path}\")"],"metadata":{"id":"YDy11qY0VIdD"},"execution_count":null,"outputs":[]}]}